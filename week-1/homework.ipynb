{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(list_file_name: list):\n",
    "    for file_name in list_file_name:\n",
    "        # check if file already exist\n",
    "        if not os.path.exists(f\"./data/{file_name}\"): # Or folder, will return true or false\n",
    "            if not os.path.exists(\"./data/\"):\n",
    "                os.mkdir(\"./data/\")\n",
    "            site_url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file_name}\"\n",
    "            file_name = f\"./data/{file_name}\"\n",
    "            urllib.request.urlretrieve(site_url, filename=file_name)\n",
    "            print(f\"load file: {file_name}\")\n",
    "        else:\n",
    "            print(f'file {file_name} already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file yellow_tripdata_2023-01.parquet already exist\n",
      "file yellow_tripdata_2023-02.parquet already exist\n"
     ]
    }
   ],
   "source": [
    "list_of_file = [\"yellow_tripdata_2023-01.parquet\", \"yellow_tripdata_2023-02.parquet\"]\n",
    "load_data(list_of_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "- 16\n",
    "- 17\n",
    "- 18\n",
    "- 19 (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns count: 19\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/yellow_tripdata_2023-01.parquet')\n",
    "print(f\"columns count: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "- 32.59\n",
    "- 42.59 (x)\n",
    "- 52.59\n",
    "- 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std of duration is 42.59435124195458 mins\n"
     ]
    }
   ],
   "source": [
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "print(f\"std of duration is {df['duration'].std()} mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "- 90%\n",
    "- 92%\n",
    "- 95%\n",
    "- 98% (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fraction of the records left = 98.1220282212598\n"
     ]
    }
   ],
   "source": [
    "df_drop = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "record_left = (len(df_drop)/ len(df)) * 100\n",
    "print(f\" fraction of the records left = {record_left}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "- 2\n",
    "- 155\n",
    "- 345\n",
    "- 515 (x)\n",
    "- 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Booklyn\\AppData\\Local\\Temp\\ipykernel_13476\\2496641530.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drop[categorical] = df_drop[categorical].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality of this matrix: (3009173, 515)\n"
     ]
    }
   ],
   "source": [
    "# Specify the categorical columns\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "# Convert categorical columns to strings\n",
    "df_drop[categorical] = df_drop[categorical].astype(str)\n",
    "# Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "train_dicts = df_drop[categorical].to_dict(orient='records')\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# Get a feature matrix from it\n",
    "print(f\"dimensionality of this matrix: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters\n",
    "Calculate the RMSE of the model on the training data\n",
    "What's the RMSE on train?\n",
    "\n",
    "- 3.64\n",
    "- 7.64 (x)\n",
    "- 11.64\n",
    "- 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_drop[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 7.6492611527240895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Booklyn\\miniconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f\"rmse: {mean_squared_error(y_train, y_pred, squared=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "- 3.81\n",
    "- 7.81 (x)\n",
    "- 11.81\n",
    "- 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(file_name):\n",
    "    df = pd.read_parquet(file_name)\n",
    "    # transformed\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    # Specify the categorical columns\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_df('./data/yellow_tripdata_2023-01.parquet')\n",
    "df_val = read_df('./data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "dv = DictVectorizer()\n",
    "train_dicts = df_train[categorical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "val_dicts = df_val[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 7.811817646307258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Booklyn\\miniconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f\"rmse: {mean_squared_error(y_val, y_pred, squared=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
